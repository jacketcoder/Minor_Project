{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class convertCVtoText:\n",
    "    @staticmethod\n",
    "    def startConversion(fileName):\n",
    "        import PyPDF2\n",
    "        pdfFileObj = open(fileName,'rb')     #'rb' for read binary mode\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        noOfPages=pdfReader.numPages\n",
    "        text=\"\"\n",
    "        for pages in range(0,pdfReader.numPages):\n",
    "            pageObj = pdfReader.getPage(pages)          #'9' is the page number\n",
    "            text+=pageObj.extractText()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class regularExp:\n",
    "    @staticmethod\n",
    "    def normalizeText(text):\n",
    "        norText=\"\"\n",
    "        returnText=\"\"\n",
    "        \n",
    "        import re\n",
    "        norText+= re.sub(r'[^a-zA-Z ]',r' ',text)\n",
    "        returnText+=re.sub(' +',' ',norText)\n",
    "        norText=\"\"\n",
    "        norText+=re.sub(r'([A-Z])', lambda pat: pat.group(1).lower(), returnText)\n",
    "        return norText\n",
    "    @staticmethod\n",
    "    def Stemmer(text):\n",
    "        from nltk.stem import PorterStemmer\n",
    "        import nltk\n",
    "        words=nltk.word_tokenize(text)\n",
    "        stemmer = PorterStemmer()\n",
    "        singles = [stemmer.stem(word) for word in words]\n",
    "        #print(singles)\n",
    "        singles=list(set(singles))\n",
    "        #print(singles)\n",
    "        stemmedText=\" \".join(singles)\n",
    "        #print(stemmedText)\n",
    "        return stemmedText\n",
    "       \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NLTKHelper:\n",
    "    @staticmethod\n",
    "    def findDocumentMatrix(totalCVText,minFrequency,vocab):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        if vocab is None:\n",
    "            vectorizer=CountVectorizer(stop_words='english',min_df=minFrequency)\n",
    "        elif minFrequency is None:\n",
    "            vectorizer=CountVectorizer(stop_words='english',vocabulary=vocab)\n",
    "        else:\n",
    "            vectorizer=CountVectorizer(stop_words='english')\n",
    "        documentMatrix=vectorizer.fit_transform(totalCVText)\n",
    "        vocabulary=vectorizer.vocabulary_\n",
    "        return documentMatrix,vocabulary     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CV:\n",
    "     def __init__(self,path):\n",
    "            self.fileName=path\n",
    "            self.text=convertCVtoText.startConversion(self.fileName)\n",
    "            self.cleanText=regularExp.normalizeText(self.text)\n",
    "            self.stemedText=regularExp.Stemmer(self.cleanText)\n",
    "            self.featureVector=[]\n",
    "            #self.cleanTextNew=regularExp.normalizeText(self.stemedText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class relevantWords:\n",
    "    def __init__(self):\n",
    "        self.category=[\"role\",\"language\",\"softwarePackage\",\"experienceSkill\",\"os\"]\n",
    "        self.jobs=[\"database Engineer\",\"network engineer\",\"software tester\",\"web designer\"]\n",
    "        self.role=[]\n",
    "        self.language=[]\n",
    "        self.softwarePackage=[]\n",
    "        self.experienceSkill=[]\n",
    "        self.os=[]\n",
    "        self.categoryDictionary={}\n",
    "        self.relevantDictionary={}\n",
    "        self.relevantWordList=[]\n",
    "    def enterWords(self,category,words):\n",
    "        if (category in self.category):\n",
    "            if(category==self.category[0]):\n",
    "                for word in words:\n",
    "                    self.role.append(word)\n",
    "            elif(category==self.category[1]):\n",
    "                for word in words:\n",
    "                    self.language.append(word)\n",
    "            elif(category==self.category[2]):\n",
    "                for word in words:\n",
    "                    self.softwarePackage.append(word)\n",
    "            elif(category==self.category[3]):\n",
    "                for word in words:\n",
    "                    self.experienceSkill.append(word)\n",
    "            elif(category==self.category[4]):\n",
    "                for word in words:\n",
    "                    self.os.append(word)\n",
    "        else:\n",
    "            print(\"category not matched\")\n",
    "    def updateDict(self,jobName):\n",
    "        tempDict={}\n",
    "        tempDict.update({self.category[0]:self.role})\n",
    "        tempDict.update({self.category[1]:self.language})\n",
    "        tempDict.update({self.category[2]:self.softwarePackage})\n",
    "        tempDict.update({self.category[3]:self.experienceSkill})\n",
    "        tempDict.update({self.category[4]:self.os})\n",
    "        self.role=[]\n",
    "        self.language=[]\n",
    "        self.softwarePackage=[]\n",
    "        self.experienceSkill=[]\n",
    "        self.os=[]\n",
    "#         if(not(self.readfileMode(\"relevantDictionary\")) is None):\n",
    "#             self.relevantDictionary=self.readfileMode(\"relevantDictionary\")\n",
    "        self.relevantDictionary.update({jobName:tempDict})\n",
    "#         self.writefileMode(\"relevantDictionary\",self.relevantDictionary)\n",
    "    def readfileMode(self,fileName):\n",
    "        try:\n",
    "            with open(fileName+\".json\",\"r\") as file:\n",
    "                data=json.load(file)\n",
    "            file.close()\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(\"error in filemode.\\n Error is\"+str(e))\n",
    "            return None\n",
    "    def writefileMode(self,fileName,data):\n",
    "        try:\n",
    "            with open(fileName+\".json\",\"w\") as file:\n",
    "                json.dump(data,file)\n",
    "            file.close()\n",
    "        except Exception as e:\n",
    "            print(\"error in filemode.\\n Error is\"+str(e))\n",
    "    def getRelevantWords(self,source=None):\n",
    "        relevantWords=[]\n",
    "        if(source is None):\n",
    "            source=self.relevantDictionary\n",
    "        for key,value in source.items():\n",
    "            for key1,value1 in value.items():\n",
    "                for word in value1:\n",
    "                    relevantWords.append(word)\n",
    "        return set(relevantWords)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rv=relevantWords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rv.enterWords(\"role\",[\"communication\",\"network\",\"server\",\"client\"])\n",
    "rv.enterWords(\"language\",[\"python\",\"bash\",\"php\",\"c++\",\"c\"])\n",
    "rv.enterWords(\"softwarePackage\",[])\n",
    "rv.enterWords(\"experienceSkill\",[\"lan\",\"cloud\",\"wan\",\"man\",\"gan\",\"cyber\",\"security\",\"dns\",\"iot\",\"virtulization\"])\n",
    "rv.enterWords(\"os\",[\"unix\",\"windows\",\"linux\"])\n",
    "rv.updateDict(\"network enginer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevantWords=[\n",
    "#    'adobe',\n",
    "# 'com',\n",
    "#  'creative',\n",
    "#  'css',\n",
    "#  'design',\n",
    "#  'designer',\n",
    "#  'experience',\n",
    "#  'graphic',\n",
    "#  'html',\n",
    "#  'http',\n",
    "#  'links',\n",
    "# 'media',\n",
    "# 'photoshop',\n",
    "# 'skills',\n",
    "#  'web',\n",
    "#  'website',\n",
    "#  'www',\n",
    "#             'agile',\n",
    "#  'analysis',\n",
    "#  'application',\n",
    "#  'cases',\n",
    "#  'data',\n",
    "#  'design',\n",
    "#  'development',\n",
    "#  'functional',\n",
    "#  'information',\n",
    "#  'process',\n",
    "#  'project',\n",
    "#  'qa',\n",
    "#  'quality',\n",
    "#  'server',\n",
    "#  'skills',\n",
    "#  'software',\n",
    "#  'sql',\n",
    "#  'systems',\n",
    "#  'technical',\n",
    "#  'test',\n",
    "#  'tools',\n",
    "# 'web',\n",
    "#  'windows',\n",
    "'access',\n",
    " 'asa',\n",
    " 'bgp',\n",
    " 'cisco',\n",
    "'eigrp',\n",
    "'engineer',\n",
    "'firewall',\n",
    "'ios',\n",
    " 'ip',\n",
    " 'lan',\n",
    " 'monitoring',\n",
    " 'network',\n",
    "'ospf',\n",
    "'protocols',\n",
    " 'routers',\n",
    "'server',\n",
    "'skills',\n",
    "'switches',\n",
    "'tcp',\n",
    "'technical',\n",
    "'vpn',\n",
    " 'wan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CVManager:\n",
    "    def __init__(self):\n",
    "        self.CVAdded=None\n",
    "        #self.database=databaseHandler()\n",
    "        self.CVList=[]\n",
    "        self.CVFileName=[]\n",
    "        self.fileNamesWithPath=[]\n",
    "        self.CVTextColl=[]\n",
    "        self.CVTextCollTest=[]\n",
    "        self.documentMatrix=[]\n",
    "        self.vocabulary={}\n",
    "        self.documentMatrixTest=[]\n",
    "        self.vocabularyTest={}\n",
    "    def list_CVs(self,rootPath):\n",
    "        import os,json\n",
    "#             if(os.path.exists(\"CVNameList.json\")):\n",
    "#                 print(\"here\")\n",
    "#                 with open(\"CVNameList.json\",\"r\") as file:\n",
    "#                     self.fileNamesWithPath=json.load(file)\n",
    "#             else:   \n",
    "        for root, dirs, files in os.walk(rootPath):\n",
    "            for name in files:\n",
    "                self.CVFileName.append(name)\n",
    "                self.fileNamesWithPath.append(os.path.join(root, name))\n",
    "#                 with open(\"CVNameList.json\",\"w\") as file:\n",
    "#                     json.dump(self.fileNamesWithPath,file)\n",
    "#                 file.close()\n",
    "               \n",
    "    def collectCV(self):\n",
    "            for cvPath in self.fileNamesWithPath:\n",
    "                try:\n",
    "                    newCV=CV(cvPath)\n",
    "                    self.CVList.append(newCV)\n",
    "                    #print(\"%s named CV is already in database\"%cvName)\n",
    "                except Exception as e:\n",
    "                    print(cvPath)\n",
    "                    print(\"in collection of CV \\t\"+str(e))\n",
    "            \n",
    "    def collectCVText(self):\n",
    "        self.CVTextColl=[]\n",
    "        self.CVTextCollTest=[]\n",
    "        for cv in self.CVList:\n",
    "            self.CVTextColl.append(cv.cleanText) \n",
    "            self.CVTextCollTest.append(cv.stemedText) \n",
    "    def findDocumentMatrix(self,minFrequency,vocab):\n",
    "        import json\n",
    "        try:\n",
    "                self.documentMatrix=[]\n",
    "                self.vocabulary=[]\n",
    "                self.documentMatrixTest=[]\n",
    "                self.vocabularyTest=[]\n",
    "                self.collectCVText()\n",
    "                self.documentMatrix,self.vocabulary=NLTKHelper.findDocumentMatrix(self.CVTextColl,minFrequency,vocab)\n",
    "                self.documentMatrixTest,self.vocabularyTest=NLTKHelper.findDocumentMatrix(self.CVTextCollTest,minFrequency,vocab)\n",
    "#                 with open(\"wholeCVText.json\",\"w\") as file:\n",
    "#                     json.dump(self.CVTextColl,file)\n",
    "#                 file.close()\n",
    "#                 with open(\"wholeCVTextTest.json\",\"w\") as file:\n",
    "#                     json.dump(self.CVTextCollTest,file)\n",
    "#                 file.close()\n",
    "#             else:\n",
    "#                 with open(\"wholeCVText.json\",\"r\") as file:\n",
    "#                     self.CVTextColl=json.load(file)\n",
    "#                 file.close()\n",
    "#                 with open(\"wholeCVTextTest.json\",\"r\") as file:\n",
    "#                     self.CVTextCollTest=json.load(file)\n",
    "#                 file.close()\n",
    "#                 self.documentMatrix,self.vocabulary=NLTKHelper.findDocumentMatrix(self.CVTextColl,minFrequency,vocab)\n",
    "#                 self.documentMatrixTest,self.vocabularyTest=NLTKHelper.findDocumentMatrix(self.CVTextCollTest,minFrequency,vocab)\n",
    "        except Exception as e:\n",
    "            print(\"in reading/writing of saved files \\t\"+str(e))\n",
    "    def normalizeFeatureVector(self):\n",
    "        from sklearn.preprocessing import normalize\n",
    "        import numpy as np\n",
    "        featureSet=normalize(self.documentMatrix.toarray(),float64)\n",
    "        for cv,cvNum in zip(manager.CVList,range(0,len(manager.CVFileName)-1)):\n",
    "            for featureRow in range(0,len(self.vocabularyTest)-1):\n",
    "                cv.featureVector.append(featureSet[cvNum][featureRow])\n",
    "                \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manager=CVManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manager.list_CVs(\"CV coll\\\\sagar\\\\test\\\\network engineer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manager.collectCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use this function to test the feature vector given by relevant words\n",
    "manager.findDocumentMatrix(None,set(relevantWords))\n",
    "#use this function to find the most ferquently words as given in function\n",
    "#it will help to find the relevant word for that post\n",
    "#manager.findDocumentMatrix(40,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function. [validation.py:429]\n"
     ]
    }
   ],
   "source": [
    "manager.normalizeFeatureVector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample. [validation.py:395]\n",
      "DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function. [validation.py:429]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "featureSet=normalize(manager.documentMatrix.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05763904,  0.05763904,  0.05763904,  0.23055617,  0.05763904,\n",
       "        0.05763904,  0.        ,  0.05763904,  0.28819521,  0.17291713,\n",
       "        0.        ,  0.86458563,  0.        ,  0.        ,  0.05763904,\n",
       "        0.11527808,  0.05763904,  0.05763904,  0.        ,  0.17291713,\n",
       "        0.        ,  0.11527808])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0576390417704\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(manager.CVList[0].featureVector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(manager.documentMatrix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access': 0,\n",
       " 'asa': 1,\n",
       " 'bgp': 2,\n",
       " 'cisco': 3,\n",
       " 'eigrp': 4,\n",
       " 'engineer': 5,\n",
       " 'firewall': 6,\n",
       " 'ios': 7,\n",
       " 'ip': 8,\n",
       " 'lan': 9,\n",
       " 'monitoring': 10,\n",
       " 'network': 11,\n",
       " 'ospf': 12,\n",
       " 'protocols': 13,\n",
       " 'routers': 14,\n",
       " 'server': 15,\n",
       " 'skills': 16,\n",
       " 'switches': 17,\n",
       " 'tcp': 18,\n",
       " 'technical': 19,\n",
       " 'vpn': 20,\n",
       " 'wan': 21}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# import pip\n",
    "# pip.main(['install', \"PyPDF2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for z in x.data:\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for cv,cvNum in zip(manager.CVList,range(0,len(manager.CVFileName)-1)):\n",
    "#     print(cv.fileName)\n",
    "#     for featureRow in range(0,len(manager.vocabularyTest)-1):\n",
    "#                    print(x[cvNum][featureRow])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters=2, The Silhouette Coefficient is 0.6808136202787941\n",
      "For n_clusters=3, The Silhouette Coefficient is 0.5525919445309032\n",
      "For n_clusters=4, The Silhouette Coefficient is 0.49782569008681465\n",
      "For n_clusters=5, The Silhouette Coefficient is 0.4885175508654504\n",
      "For n_clusters=6, The Silhouette Coefficient is 0.3698520037561342\n",
      "For n_clusters=7, The Silhouette Coefficient is 0.3508759604375027\n",
      "For n_clusters=8, The Silhouette Coefficient is 0.3631199946211778\n",
      "For n_clusters=9, The Silhouette Coefficient is 0.3349161037628484\n",
      "For n_clusters=10, The Silhouette Coefficient is 0.32708345216924956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = load_iris().data\n",
    "y = load_iris().target\n",
    "\n",
    "for n_cluster in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=n_cluster).fit(X)\n",
    "    label = kmeans.labels_\n",
    "    sil_coeff = silhouette_score(X, label, metric='euclidean')\n",
    "    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 614 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(manager.documentMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
