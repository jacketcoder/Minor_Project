{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class convertCVtoText:\n",
    "    @staticmethod\n",
    "    def startConversion(fileName):\n",
    "        import PyPDF2\n",
    "        pdfFileObj = open(fileName,'rb')     #'rb' for read binary mode\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        noOfPages=pdfReader.numPages\n",
    "        text=\"\"\n",
    "        for pages in range(0,pdfReader.numPages):\n",
    "            pageObj = pdfReader.getPage(pages)          #'9' is the page number\n",
    "            text+=pageObj.extractText()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class regularExp:\n",
    "    @staticmethod\n",
    "    def normalizeText(text):\n",
    "        norText=\"\"\n",
    "        returnText=\"\"\n",
    "        \n",
    "        import re\n",
    "        norText+= re.sub(r'[^a-zA-Z ]',r' ',text)\n",
    "        returnText+=re.sub(' +',' ',norText)\n",
    "        norText=\"\"\n",
    "        norText+=re.sub(r'([A-Z])', lambda pat: pat.group(1).lower(), returnText)\n",
    "        return norText\n",
    "    @staticmethod\n",
    "    def Stemmer(text):\n",
    "        from nltk.stem import PorterStemmer\n",
    "        import nltk\n",
    "        words=nltk.word_tokenize(text)\n",
    "        stemmer = PorterStemmer()\n",
    "        singles = [stemmer.stem(word) for word in words]\n",
    "        #print(singles)\n",
    "        singles=list(set(singles))\n",
    "        #print(singles)\n",
    "        stemmedText=\" \".join(singles)\n",
    "        #print(stemmedText)\n",
    "        return stemmedText\n",
    "       \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NLTKHelper:\n",
    "    @staticmethod\n",
    "    def findDocumentMatrix(totalCVText,minFrequency,vocab):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        if vocab is None:\n",
    "            vectorizer=CountVectorizer(stop_words='english',min_df=minFrequency)\n",
    "        elif minFrequency is None:\n",
    "            vectorizer=CountVectorizer(stop_words='english',vocabulary=vocab)\n",
    "        else:\n",
    "            vectorizer=CountVectorizer(stop_words='english')\n",
    "        documentMatrix=vectorizer.fit_transform(totalCVText)\n",
    "        vocabulary=vectorizer.vocabulary_\n",
    "        return documentMatrix,vocabulary     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CV:\n",
    "     def __init__(self,path):\n",
    "            self.fileName=path\n",
    "            self.text=convertCVtoText.startConversion(self.fileName)\n",
    "            self.cleanText=regularExp.normalizeText(self.text)\n",
    "            self.stemedText=regularExp.Stemmer(self.cleanText)\n",
    "            self.featureVector=[]\n",
    "            #self.cleanTextNew=regularExp.normalizeText(self.stemedText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class relevantWords:\n",
    "    def __init__(self):\n",
    "        self.category=[\"role\",\"language\",\"softwarePackage\",\"experienceSkill\",\"os\"]\n",
    "        self.jobs=[\"database Engineer\",\"network engineer\",\"software tester\",\"web designer\"]\n",
    "        self.role=[]\n",
    "        self.language=[]\n",
    "        self.softwarePackage=[]\n",
    "        self.experienceSkill=[]\n",
    "        self.os=[]\n",
    "        self.categoryDictionary={}\n",
    "        self.relevantDictionary={}\n",
    "        self.relevantWordList=[]\n",
    "    def enterWords(self,category,words):\n",
    "        if (category in self.category):\n",
    "            if(category==self.category[0]):\n",
    "                for word in words:\n",
    "                    self.role.append(word)\n",
    "            elif(category==self.category[1]):\n",
    "                for word in words:\n",
    "                    self.language.append(word)\n",
    "            elif(category==self.category[2]):\n",
    "                for word in words:\n",
    "                    self.softwarePackage.append(word)\n",
    "            elif(category==self.category[3]):\n",
    "                for word in words:\n",
    "                    self.experienceSkill.append(word)\n",
    "            elif(category==self.category[4]):\n",
    "                for word in words:\n",
    "                    self.os.append(word)\n",
    "        else:\n",
    "            print(\"category not matched\")\n",
    "    def updateDict(self,jobName):\n",
    "        tempDict={}\n",
    "        tempDict.update({self.category[0]:self.role})\n",
    "        tempDict.update({self.category[1]:self.language})\n",
    "        tempDict.update({self.category[2]:self.softwarePackage})\n",
    "        tempDict.update({self.category[3]:self.experienceSkill})\n",
    "        tempDict.update({self.category[4]:self.os})\n",
    "        self.role=[]\n",
    "        self.language=[]\n",
    "        self.softwarePackage=[]\n",
    "        self.experienceSkill=[]\n",
    "        self.os=[]\n",
    "#         if(not(self.readfileMode(\"relevantDictionary\")) is None):\n",
    "#             self.relevantDictionary=self.readfileMode(\"relevantDictionary\")\n",
    "        self.relevantDictionary.update({jobName:tempDict})\n",
    "#         self.writefileMode(\"relevantDictionary\",self.relevantDictionary)\n",
    "    def readfileMode(self,fileName):\n",
    "        try:\n",
    "            with open(fileName+\".json\",\"r\") as file:\n",
    "                data=json.load(file)\n",
    "            file.close()\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(\"error in filemode.\\n Error is\"+str(e))\n",
    "            return None\n",
    "    def writefileMode(self,fileName,data):\n",
    "        try:\n",
    "            with open(fileName+\".json\",\"w\") as file:\n",
    "                json.dump(data,file)\n",
    "            file.close()\n",
    "        except Exception as e:\n",
    "            print(\"error in filemode.\\n Error is\"+str(e))\n",
    "    def getRelevantWords(self,source=None):\n",
    "        relevantWords=[]\n",
    "        if(source is None):\n",
    "            source=self.relevantDictionary\n",
    "        for key,value in source.items():\n",
    "            for key1,value1 in value.items():\n",
    "                for word in value1:\n",
    "                    relevantWords.append(word)\n",
    "        return set(relevantWords)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rv=relevantWords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rv.enterWords(\"role\",[\"communication\",\"network\",\"server\",\"client\"])\n",
    "rv.enterWords(\"language\",[\"python\",\"bash\",\"php\",\"c++\",\"c\"])\n",
    "rv.enterWords(\"softwarePackage\",[])\n",
    "rv.enterWords(\"experienceSkill\",[\"lan\",\"cloud\",\"wan\",\"man\",\"gan\",\"cyber\",\"security\",\"dns\",\"iot\",\"virtulization\"])\n",
    "rv.enterWords(\"os\",[\"unix\",\"windows\",\"linux\"])\n",
    "rv.updateDict(\"network enginer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CVManager:\n",
    "    def __init__(self):\n",
    "        self.CVAdded=None\n",
    "        #self.database=databaseHandler()\n",
    "        self.CVList=[]\n",
    "        self.CVFileName=[]\n",
    "        self.fileNamesWithPath=[]\n",
    "        self.CVTextColl=[]\n",
    "        self.CVTextCollTest=[]\n",
    "        self.documentMatrix=[]\n",
    "        self.vocabulary={}\n",
    "        self.documentMatrixTest=[]\n",
    "        self.vocabularyTest={}\n",
    "    def list_CVs(self,rootPath):\n",
    "        import os,json\n",
    "#             if(os.path.exists(\"CVNameList.json\")):\n",
    "#                 print(\"here\")\n",
    "#                 with open(\"CVNameList.json\",\"r\") as file:\n",
    "#                     self.fileNamesWithPath=json.load(file)\n",
    "#             else:   \n",
    "        for root, dirs, files in os.walk(rootPath):\n",
    "            for name in files:\n",
    "                self.CVFileName.append(name)\n",
    "                self.fileNamesWithPath.append(os.path.join(root, name))\n",
    "#                 with open(\"CVNameList.json\",\"w\") as file:\n",
    "#                     json.dump(self.fileNamesWithPath,file)\n",
    "#                 file.close()\n",
    "               \n",
    "    def collectCV(self):\n",
    "            for cvPath in self.fileNamesWithPath:\n",
    "                try:\n",
    "                    newCV=CV(cvPath)\n",
    "                    self.CVList.append(newCV)\n",
    "                    #print(\"%s named CV is already in database\"%cvName)\n",
    "                except Exception as e:\n",
    "                    print(cvPath)\n",
    "                    print(\"in collection of CV \\t\"+str(e))\n",
    "            \n",
    "    def collectCVText(self):\n",
    "        for cv in self.CVList:\n",
    "            self.CVTextColl.append(cv.cleanText) \n",
    "            self.CVTextCollTest.append(cv.stemedText) \n",
    "    def findDocumentMatrix(self,minFrequency,vocab):\n",
    "        import json\n",
    "        try:\n",
    "                self.collectCVText()\n",
    "                self.documentMatrix,self.vocabulary=NLTKHelper.findDocumentMatrix(self.CVTextColl,minFrequency,vocab)\n",
    "                self.documentMatrixTest,self.vocabularyTest=NLTKHelper.findDocumentMatrix(self.CVTextCollTest,minFrequency,vocab)\n",
    "#                 with open(\"wholeCVText.json\",\"w\") as file:\n",
    "#                     json.dump(self.CVTextColl,file)\n",
    "#                 file.close()\n",
    "#                 with open(\"wholeCVTextTest.json\",\"w\") as file:\n",
    "#                     json.dump(self.CVTextCollTest,file)\n",
    "#                 file.close()\n",
    "#             else:\n",
    "#                 with open(\"wholeCVText.json\",\"r\") as file:\n",
    "#                     self.CVTextColl=json.load(file)\n",
    "#                 file.close()\n",
    "#                 with open(\"wholeCVTextTest.json\",\"r\") as file:\n",
    "#                     self.CVTextCollTest=json.load(file)\n",
    "#                 file.close()\n",
    "#                 self.documentMatrix,self.vocabulary=NLTKHelper.findDocumentMatrix(self.CVTextColl,minFrequency,vocab)\n",
    "#                 self.documentMatrixTest,self.vocabularyTest=NLTKHelper.findDocumentMatrix(self.CVTextCollTest,minFrequency,vocab)\n",
    "        except Exception as e:\n",
    "            print(\"in reading/writing of saved files \\t\"+str(e))\n",
    "            import os\n",
    "            try:\n",
    "                os.remove(\"CVNameList.json\")\n",
    "            except Exception as e:\n",
    "                print(\"in deleting the file \\t\"+str(e))\n",
    "    def normalizeFeatureVector(self):\n",
    "        from sklearn.preprocessing import normalize\n",
    "        import numpy as np\n",
    "        vectorValue=[]\n",
    "        for key in self.vocabularyTest:\n",
    "            vectorValue.append(self.featureVectorDict[key])\n",
    "        datas = np.asarray(vectorValue, dtype=np.float)\n",
    "        datas =normalize(datas, norm='l2')\n",
    "        #converting numpy.array to list\n",
    "        for r in datas:\n",
    "            for column in r:\n",
    "                self.normalizedVectorValue.append(column)\n",
    "        print(self.normalizedVectorValue)\n",
    "                \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manager=CVManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manager.list_CVs(\"CV coll\\\\sagar\\\\network engineer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manager.collectCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use this function to test the feature vector given by relevant words\n",
    "#manager.findDocumentMatrix(None,rv.getRelevantWords())\n",
    "#use this function to find the most ferquently words as given in function\n",
    "#it will help to find the relevant word for that post\n",
    "manager.findDocumentMatrix(30,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print(len(manager.vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "print(len(manager.vocabularyTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  1 ...,  1  1  0]\n",
      " [ 0  0  0 ...,  0  0  0]\n",
      " [ 0  0  0 ...,  0  0  0]\n",
      " ..., \n",
      " [ 1  0  1 ...,  2  1  0]\n",
      " [ 3  0  1 ...,  2  0 10]\n",
      " [ 0  0  1 ...,  2  1  6]]\n"
     ]
    }
   ],
   "source": [
    "print(manager.documentMatrix.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access': 0,\n",
       " 'active': 1,\n",
       " 'additional': 2,\n",
       " 'authorized': 3,\n",
       " 'center': 4,\n",
       " 'cisco': 5,\n",
       " 'com': 6,\n",
       " 'communication': 7,\n",
       " 'computer': 8,\n",
       " 'configuration': 9,\n",
       " 'customer': 10,\n",
       " 'data': 11,\n",
       " 'design': 12,\n",
       " 'devices': 13,\n",
       " 'education': 14,\n",
       " 'email': 15,\n",
       " 'employer': 16,\n",
       " 'engineer': 17,\n",
       " 'environment': 18,\n",
       " 'equipment': 19,\n",
       " 'experience': 20,\n",
       " 'hardware': 21,\n",
       " 'implementation': 22,\n",
       " 'including': 23,\n",
       " 'information': 24,\n",
       " 'infrastructure': 25,\n",
       " 'installation': 26,\n",
       " 'ip': 27,\n",
       " 'issues': 28,\n",
       " 'june': 29,\n",
       " 'lan': 30,\n",
       " 'maintenance': 31,\n",
       " 'management': 32,\n",
       " 'manager': 33,\n",
       " 'microsoft': 34,\n",
       " 'network': 35,\n",
       " 'networking': 36,\n",
       " 'networks': 37,\n",
       " 'new': 38,\n",
       " 'office': 39,\n",
       " 'present': 40,\n",
       " 'project': 41,\n",
       " 'provided': 42,\n",
       " 'responsible': 43,\n",
       " 'routers': 44,\n",
       " 'routing': 45,\n",
       " 'security': 46,\n",
       " 'server': 47,\n",
       " 'servers': 48,\n",
       " 'service': 49,\n",
       " 'skills': 50,\n",
       " 'software': 51,\n",
       " 'support': 52,\n",
       " 'switches': 53,\n",
       " 'systems': 54,\n",
       " 'team': 55,\n",
       " 'technical': 56,\n",
       " 'technologies': 57,\n",
       " 'technology': 58,\n",
       " 'troubleshooting': 59,\n",
       " 'university': 60,\n",
       " 'using': 61,\n",
       " 'wan': 62,\n",
       " 'windows': 63,\n",
       " 'wireless': 64,\n",
       " 'work': 65,\n",
       " 'working': 66,\n",
       " 'years': 67}"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
