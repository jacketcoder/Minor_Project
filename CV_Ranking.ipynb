{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class convertCVtoText:\n",
    "    @staticmethod\n",
    "    def startConversion(fileName):\n",
    "        import PyPDF2\n",
    "        pdfFileObj = open(fileName,'rb')     #'rb' for read binary mode\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        noOfPages=pdfReader.numPages\n",
    "        text=\"\"\n",
    "        for pages in range(0,pdfReader.numPages):\n",
    "            pageObj = pdfReader.getPage(pages)          #'9' is the page number\n",
    "            text+=pageObj.extractText()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class regularExp:\n",
    "    @staticmethod\n",
    "    def normalizeText(text):\n",
    "        norText=\"\"\n",
    "        returnText=\"\"\n",
    "        \n",
    "        import re\n",
    "        norText+= re.sub(r'[^a-zA-Z ]',r' ',text)\n",
    "        returnText+=re.sub(' +',' ',norText)\n",
    "        norText=\"\"\n",
    "        norText+=re.sub(r'([A-Z])', lambda pat: pat.group(1).lower(), returnText)\n",
    "        return norText\n",
    "    @staticmethod\n",
    "    def Stemmer(text):\n",
    "        from nltk.stem import PorterStemmer\n",
    "        import nltk\n",
    "        words=nltk.word_tokenize(text)\n",
    "        stemmer = PorterStemmer()\n",
    "        singles = [stemmer.stem(word) for word in words]\n",
    "        #print(singles)\n",
    "        singles=list(set(singles))\n",
    "        #print(singles)\n",
    "        stemmedText=\" \".join(singles)\n",
    "        #print(stemmedText)\n",
    "        return stemmedText\n",
    "       \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NLTKHelper:\n",
    "    @staticmethod\n",
    "    def findDocumentMatrix(totalCVText,minFrequency,vocab):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        #vectorizer=CountVectorizer(stop_words='english',min_df=minFrequency\n",
    "        vectorizer=CountVectorizer(stop_words='english',vocabulary=vocab)\n",
    "        #vectorizer=CountVectorizer(stop_words='english')\n",
    "        documentMatrix=vectorizer.fit_transform(totalCVText)\n",
    "        vocabulary=vectorizer.vocabulary_\n",
    "        return documentMatrix,vocabulary     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CV:\n",
    "     def __init__(self,path):\n",
    "            self.fileName=path\n",
    "            self.text=convertCVtoText.startConversion(self.fileName)\n",
    "            self.cleanText=regularExp.normalizeText(self.text)\n",
    "            self.stemedText=regularExp.Stemmer(self.cleanText)\n",
    "            self.featureVector=[]\n",
    "            #self.cleanTextNew=regularExp.normalizeText(self.stemedText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCSVFile(fileName,row=None,col=None):\n",
    "    import pandas as pd\n",
    "    pd.set_option('display.max_columns', col)\n",
    "    pd.set_option('display.max_rows', row)\n",
    "    #pd.set_option('display.max_colwidth',1000)\n",
    "    return pd.read_csv(fileName)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class relevantWords:\n",
    "    def __init__(self):\n",
    "        self.category=[\"role\",\"language\",\"softwarePackage\",\"experienceSkill\",\"os\"]\n",
    "        self.jobs=[\"database Engineer\",\"network engineer\",\"software tester\",\"web designer\"]\n",
    "        self.role=[]\n",
    "        self.language=[]\n",
    "        self.softwarePackage=[]\n",
    "        self.experienceSkill=[]\n",
    "        self.os=[]\n",
    "        self.categoryDictionary={}\n",
    "        self.relevantDictionary={}\n",
    "        self.relevantWordList=[]\n",
    "    def enterWords(self,category,words):\n",
    "        if (category in self.category):\n",
    "            if(category==self.category[0]):\n",
    "                for word in words:\n",
    "                    self.role.append(word)\n",
    "            elif(category==self.category[1]):\n",
    "                for word in words:\n",
    "                    self.language.append(word)\n",
    "            elif(category==self.category[2]):\n",
    "                for word in words:\n",
    "                    self.softwarePackage.append(word)\n",
    "            elif(category==self.category[3]):\n",
    "                for word in words:\n",
    "                    self.experienceSkill.append(word)\n",
    "            elif(category==self.category[4]):\n",
    "                for word in words:\n",
    "                    self.os.append(word)\n",
    "        else:\n",
    "            print(\"category not matched\")\n",
    "    def updateDict(self,jobName):\n",
    "        tempDict={}\n",
    "        tempDict.update({self.category[0]:self.role})\n",
    "        tempDict.update({self.category[1]:self.language})\n",
    "        tempDict.update({self.category[2]:self.softwarePackage})\n",
    "        tempDict.update({self.category[3]:self.experienceSkill})\n",
    "        tempDict.update({self.category[4]:self.os})\n",
    "        self.role=[]\n",
    "        self.language=[]\n",
    "        self.softwarePackage=[]\n",
    "        self.experienceSkill=[]\n",
    "        self.os=[]\n",
    "#         if(not(self.readfileMode(\"relevantDictionary\")) is None):\n",
    "#             self.relevantDictionary=self.readfileMode(\"relevantDictionary\")\n",
    "        self.relevantDictionary.update({jobName:tempDict})\n",
    "#         self.writefileMode(\"relevantDictionary\",self.relevantDictionary)\n",
    "    def readfileMode(self,fileName):\n",
    "        try:\n",
    "            with open(fileName+\".json\",\"r\") as file:\n",
    "                data=json.load(file)\n",
    "            file.close()\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(\"error in filemode.\\n Error is\"+str(e))\n",
    "            return None\n",
    "    def writefileMode(self,fileName,data):\n",
    "        try:\n",
    "            with open(fileName+\".json\",\"w\") as file:\n",
    "                json.dump(data,file)\n",
    "            file.close()\n",
    "        except Exception as e:\n",
    "            print(\"error in filemode.\\n Error is\"+str(e))\n",
    "    def getRelevantWords(self,source=None):\n",
    "        relevantWords=[]\n",
    "        if(source is None):\n",
    "            source=self.relevantDictionary\n",
    "        for key,value in source.items():\n",
    "            for key1,value1 in value.items():\n",
    "                for word in value1:\n",
    "                    relevantWords.append(word)\n",
    "        return set(relevantWords)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rv=relevantWords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rv.enterWords(\"role\",[\"communication\",\"network\",\"server\",\"client\"])\n",
    "rv.enterWords(\"language\",[\"python\",\"bash\",\"php\",\"c++\",\"c\"])\n",
    "rv.enterWords(\"softwarePackage\",[])\n",
    "rv.enterWords(\"experienceSkill\",[\"lan\",\"cloud\",\"wan\",\"man\",\"gan\",\"cyber\",\"security\",\"dns\",\"iot\",\"virtulization\"])\n",
    "rv.enterWords(\"os\",[\"unix\",\"windows\",\"linux\"])\n",
    "rv.updateDict(\"network enginer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevantWords=[\n",
    "   'adobe',\n",
    " 'creative',\n",
    " 'css',\n",
    " 'design',\n",
    " 'designer',\n",
    " 'graphic',\n",
    " 'html',\n",
    " 'http',\n",
    " 'links',\n",
    "'media',\n",
    "'photoshop',\n",
    " 'web',\n",
    " 'website',\n",
    "'agile',\n",
    " 'analysis',\n",
    " 'application',\n",
    " 'cases',\n",
    " 'data',\n",
    " 'design',\n",
    " 'development',\n",
    " 'functional',\n",
    " 'information',\n",
    " 'process',\n",
    " 'project',\n",
    " 'qa',\n",
    " 'quality',\n",
    " 'server',\n",
    " 'skills',\n",
    " 'software',\n",
    " 'sql',\n",
    " 'systems',\n",
    " 'technical',\n",
    " 'test',\n",
    " 'tools',\n",
    "'web',\n",
    " 'windows',\n",
    "'access',\n",
    " 'asa',\n",
    " 'bgp',\n",
    " 'cisco',\n",
    "'eigrp',\n",
    "'engineer',\n",
    "'firewall',\n",
    "'ios',\n",
    " 'ip',\n",
    " 'lan',\n",
    " 'monitoring',\n",
    " 'network',\n",
    "'ospf',\n",
    "'protocols',\n",
    " 'routers',\n",
    "'server',\n",
    "'skills',\n",
    "'switches',\n",
    "'tcp',\n",
    "'technical',\n",
    "'vpn',\n",
    " 'wan'\n",
    "]\n",
    "len(set(relevantWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# relevantWords=['adobe',\n",
    "# 'advertising',\n",
    "# 'art',\n",
    "# 'campaigns',\n",
    "# 'graphic',\n",
    "# 'creative',\n",
    "# 'client',\n",
    "# 'designer',\n",
    "# 'commucnications',\n",
    "# 'graphics',\n",
    "# 'marketing',\n",
    "# 'microsoft',\n",
    "# 'photography',\n",
    "# 'photoshop',\n",
    "# 'social',\n",
    "# 'visual',\n",
    "# 'adobe',\n",
    "# 'game',\n",
    "# 'design',\n",
    "# 'development',\n",
    "# 'android',\n",
    "# 'creative',\n",
    "# 'app',\n",
    "# 'engine',\n",
    "# 'computer',\n",
    "# 'css',\n",
    "# 'engine',\n",
    "# 'mobile',\n",
    "# 'excel',\n",
    "# 'java',\n",
    "# 'javascript',\n",
    "# 'sql',\n",
    "# 'linux',\n",
    "# 'maya',\n",
    "# 'microsoft',\n",
    "# 'office',\n",
    "# 'photoshop',\n",
    "# 'python',\n",
    "# 'studio',\n",
    "# 'unity',\n",
    "# 'xml',\n",
    "# 'analysis',\n",
    "# 'administration',\n",
    "# 'client',\n",
    "# 'communication',\n",
    "# 'company',\n",
    "# 'corporate',\n",
    "# 'director',\n",
    "# 'database',\n",
    "# 'employees',\n",
    "# 'leadership',\n",
    "# 'excel',\n",
    "# 'java',\n",
    "# 'hiring',\n",
    "# 'interviewing',\n",
    "# 'manage',\n",
    "# 'ms',\n",
    "# 'interviews',\n",
    "# 'issues',\n",
    "# 'manager',\n",
    "# 'meetings',\n",
    "# 'marketing',\n",
    "# 'resource',\n",
    "# 'office',\n",
    "# 'orientation',\n",
    "# 'recruiter',\n",
    "# 'recruitment',\n",
    "# 'policies',\n",
    "# 'strategics',\n",
    "# 'web',\n",
    "# 'executie',\n",
    "# 'compliance',\n",
    "# 'administration',\n",
    "# 'tracking',\n",
    "# 'analysis',\n",
    "# 'agile',\n",
    "# 'coordination',\n",
    "# 'corporation',\n",
    "# 'computer',\n",
    "# 'database',\n",
    "# 'business',\n",
    "# 'documenation',\n",
    "# 'html',\n",
    "# 'sales',\n",
    "# 'specifications',\n",
    "# 'maintainance',\n",
    "# 'equipment',\n",
    "# 'design',\n",
    "# 'director',\n",
    "# 'database',\n",
    "# 'development',\n",
    "# 'engineer',\n",
    "# 'excel',\n",
    "# 'integration',\n",
    "# 'leadership',\n",
    "# 'professional',\n",
    "# 'scheduling',\n",
    "# 'microsoft',\n",
    "# 'management',\n",
    "# 'office',\n",
    "# 'technical',\n",
    "# 'technology',\n",
    "# 'systems',\n",
    "# 'analysis',\n",
    "# 'computer',\n",
    "# 'data',\n",
    "# 'design',\n",
    "# 'excel',\n",
    "# 'inspection',\n",
    "# 'inspector',\n",
    "# 'office',\n",
    "# 'technical',\n",
    "# 'programming',\n",
    "# 'information',\n",
    "# 'java',\n",
    "# 'microsoft',\n",
    "# 'testing',\n",
    "# 'test',\n",
    "# 'technical',\n",
    "# 'visual',\n",
    "# 'management',\n",
    "# 'responsible',\n",
    "# 'training',\n",
    "# 'quality',\n",
    "# 'skills',\n",
    "# 'web',\n",
    "# 'software'\n",
    "#  'agile','ajax','angularjs','ant','apache','api','asp','aws','bootstrap','cloud','css'\n",
    "# 'dhtml','eclipse','dreamweaver','ejb','excel','github','java','javascript','jquery','json',\n",
    "# 'linkedin','mvc','mysql','netbeans','nodejs','oracle','perl','php','photoshop','pvt','reactjs',\n",
    "# 'ruby','scrum','solaris','sublime','svn','wcf','websphere','wpf','xsl','wsdl','vb','uat','analysis','authorized','client',\n",
    "# 'database','excel','information','javascript','project','services','sql','web','manager','visual','css','database',\n",
    "# 'engineering','framework','html','java','javascript','jquery','project','sql','studio','technical','visual','web','server','net',\n",
    "# 'adobe','agile','ajax','android','angularjs','apache','api','asp','aws',\n",
    "# 'backend','bootstrap','cloud','css','database','dhtml',\n",
    "# 'dreamweaver','eclipse','ejb','excel','github','gui','hibernate',\n",
    "# 'html','http','ibm','ios','ip','java','javascript','jquery','json','junit','linkedin',\n",
    "# 'mongodb','mvc','mysql','net','nodejs','oracle','php','pvt','python','ruby','scrum',\n",
    "# 'sdlc','soap','sql','swift','svn','tfs','tomcat','ui','ux','wcf','xml','xhtml','xslt'\n",
    "# 'adobe','css','html','http','illustrator','indesign','interface','graphic',\n",
    "# 'photoshop','invision','mobile','mockups','sketch','software','suite','ui',\n",
    "# 'ux','website'\n",
    "# ]\n",
    "# print(len(relevantWords))\n",
    "# print(len(set(relevantWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# relevantWords=['agile','ajax','angularjs','ant','apache','api','asp','aws','bootstrap','cloud','css'\n",
    "# 'dhtml','eclipse','dreamweaver','ejb','excel','github','java','javascript','jquery','json',\n",
    "# 'linkedin','mvc','mysql','netbeans','nodejs','oracle','perl','php','photoshop','pvt','reactjs',\n",
    "# 'ruby','scrum','solaris','sublime','svn','wcf','websphere','wpf','xsl','wsdl','vb','uat','analysis','authorized','client',\n",
    "# 'database','excel','information','javascript','project','services','sql','web','manager','visual','css','database',\n",
    "# 'engineering','framework','html','java','javascript','jquery','project','sql','studio','technical','visual','web','server','net',\n",
    "# 'adobe','agile','ajax','android','angularjs','apache','api','asp','aws',\n",
    "# 'backend','bootstrap','cloud','css','database','dhtml',\n",
    "# 'dreamweaver','eclipse','ejb','excel','github','gui','hibernate',\n",
    "# 'html','http','ibm','ios','ip','java','javascript','jquery','json','junit','linkedin',\n",
    "# 'mongodb','mvc','mysql','net','nodejs','oracle','php','pvt','python','ruby','scrum',\n",
    "# 'sdlc','soap','sql','swift','svn','tfs','tomcat','ui','ux','wcf','xml','xhtml','xslt'\n",
    "# 'adobe','css','html','http','illustrator','indesign','interface','graphic',\n",
    "# 'photoshop','invision','mobile','mockups','sketch','software','suite','ui',\n",
    "# 'ux','website'\n",
    "# ]\n",
    "# print(len(relevantWords))\n",
    "# print(len(set(relevantWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    @staticmethod\n",
    "    def findclusterInfo(data):\n",
    "        from sklearn.metrics import silhouette_score\n",
    "        from sklearn.cluster import KMeans\n",
    "        clusterInfo={}\n",
    "        for n_cluster in range(2, 11):\n",
    "            kmeans = KMeans(n_clusters=n_cluster).fit(data)\n",
    "            label = kmeans.labels_\n",
    "            sil_coeff = silhouette_score(data, label, metric='euclidean')\n",
    "            print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))\n",
    "            clusterInfo.update({n_cluster:float(sil_coeff)})\n",
    "        return clusterInfo\n",
    "    def clusterData(clusterNumber,data):\n",
    "        from sklearn.cluster import KMeans\n",
    "        kmeans = KMeans(n_clusters=clusterNumber).fit(data)\n",
    "        return kmeans;\n",
    "    def getTopWords(means,totalCluster):\n",
    "        from ReliefF import ReliefF as rf\n",
    "        wordsIndex=[]\n",
    "        import numpy as np\n",
    "        r1=rf(n_neighbors=totalCluster-1)\n",
    "        centroids=means.cluster_centers_\n",
    "        labels=means.labels_\n",
    "        topfeatures=r1.fit_transform(centroids,labels)\n",
    "        import numpy as np\n",
    "        for no1,eachCluster in enumerate(centroids):\n",
    "            for no2,eachTopfeatureCluster in enumerate(topfeatures):\n",
    "                if(no1==no2):\n",
    "                    data=np.where(np.in1d(eachCluster,eachTopfeatureCluster))[0]\n",
    "            wordsIndex.append(data)\n",
    "        return wordsIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CVManager:\n",
    "    def __init__(self):\n",
    "     \n",
    "        self.CVAdded=None\n",
    "        #self.database=databaseHandler()\n",
    "        self.CVList=[]\n",
    "        self.cvsFile=\"documentMatrix.csv\"\n",
    "        self.CVFileName=[]\n",
    "        self.fileNamesWithPath=[]\n",
    "        self.CVTextColl=[]\n",
    "        self.CVTextCollTest=[]\n",
    "        self.documentMatrix=[]\n",
    "        self.normalizedFeatureSet=[]\n",
    "        self.vocabulary={}\n",
    "        self.documentMatrixTest=[]\n",
    "        self.vocabularyTest={}\n",
    "        self.clusterInfo={}\n",
    "        self.clustersToForm=None\n",
    "        self.kMeans=None\n",
    "        self.impFeaturesIndexList=[]\n",
    "    def list_CVs(self,rootPath):\n",
    "        import os,json  \n",
    "        for root, dirs, files in os.walk(rootPath):\n",
    "            for name in files:\n",
    "                self.CVFileName.append(name)\n",
    "                self.fileNamesWithPath.append(os.path.join(root, name))\n",
    "               \n",
    "    def collectCV(self):\n",
    "            for cvPath in self.fileNamesWithPath:\n",
    "                try:\n",
    "                    newCV=CV(cvPath)\n",
    "                    self.CVList.append(newCV)\n",
    "                except Exception as e:\n",
    "                    print(cvPath)\n",
    "                    print(\"in collection of CV \\t\"+str(e))\n",
    "            \n",
    "    def collectCVText(self):\n",
    "        self.CVTextColl=[]\n",
    "        self.CVTextCollTest=[]\n",
    "        for cv in self.CVList:\n",
    "            self.CVTextColl.append(cv.cleanText) \n",
    "            self.CVTextCollTest.append(cv.stemedText) \n",
    "    def findDocumentMatrix(self,minFrequency,vocab):\n",
    "        import pandas as pd\n",
    "        import json\n",
    "        try:\n",
    "                self.documentMatrix=[]\n",
    "                self.vocabulary=[]\n",
    "                self.documentMatrixTest=[]\n",
    "                self.vocabularyTest=[]\n",
    "                self.collectCVText()\n",
    "                self.documentMatrix,self.vocabulary=NLTKHelper.findDocumentMatrix(self.CVTextColl,minFrequency,vocab)\n",
    "                df = pd.DataFrame(self.documentMatrix.toarray())\n",
    "                df.to_csv(self.cvsFile)\n",
    "                \n",
    "                self.documentMatrixTest,self.vocabularyTest=NLTKHelper.findDocumentMatrix(self.CVTextCollTest,minFrequency,vocab)\n",
    "        except Exception as e:\n",
    "            print(\"in reading/writing of saved files \\t\"+str(e))\n",
    "    def normalizeFeatureVector(self):\n",
    "        from sklearn.preprocessing import normalize\n",
    "        import numpy as np\n",
    "        self.normalizedFeatureSet=normalize(self.documentMatrix.toarray())\n",
    "        for cv,cvNum in zip(manager.CVList,range(0,len(manager.CVFileName)-1)):\n",
    "            for featureRow in range(0,len(self.vocabularyTest)-1):\n",
    "                cv.featureVector.append(self.normalizedFeatureSet[cvNum][featureRow])\n",
    "                \n",
    "    def getClusterNumber(self):\n",
    "        self.clusterInfo=Clustering.findclusterInfo(self.normalizedFeatureSet)\n",
    "        maxValue=max(self.clusterInfo.values())\n",
    "        max_keys = [k for k, v in self.clusterInfo.items() if v == maxValue]\n",
    "        if(len(max_keys)==1):\n",
    "            for x in max_keys:\n",
    "                self.clustersToForm=x\n",
    "        else:\n",
    "            print(\"2 keys,confusion\")\n",
    "    def clusterData(self):\n",
    "        self.getClusterNumber()\n",
    "        self.kMeans=Clustering.clusterData(self.clustersToForm,self.normalizedFeatureSet)\n",
    "        self.getTopWords()\n",
    "    def getTopWords(self):\n",
    "        self.impFeaturesIndexList=[]\n",
    "        self.impFeaturesIndexList=Clustering.getTopWords(self.kMeans,self.clustersToForm)\n",
    "        for impFeaturesRow in self.impFeaturesIndexList:\n",
    "            for count in impFeaturesRow:\n",
    "                print(list(self.vocabulary.keys())[list(self.vocabulary.values()).index(count)])\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manager=CVManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manager.list_CVs(\"CV coll\\\\combo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manager.collectCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use this function to test the feature vector given by relevant words\n",
    "manager.findDocumentMatrix(None,set(relevantWords))\n",
    "#use this function to find the most ferquently words as given in function\n",
    "#it will help to find the relevant word for that post\n",
    "#manager.findDocumentMatrix(40,None)\n",
    "#manager.normalizedFeatureSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function. [validation.py:429]\n"
     ]
    }
   ],
   "source": [
    "manager.normalizeFeatureVector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters=2, The Silhouette Coefficient is 0.14937239134335722\n",
      "For n_clusters=3, The Silhouette Coefficient is 0.1442418687686594\n",
      "For n_clusters=4, The Silhouette Coefficient is 0.1645165689837933\n",
      "For n_clusters=5, The Silhouette Coefficient is 0.16215454982127928\n",
      "For n_clusters=6, The Silhouette Coefficient is 0.1711837131832535\n",
      "For n_clusters=7, The Silhouette Coefficient is 0.17440181553747525\n",
      "For n_clusters=8, The Silhouette Coefficient is 0.17927011315395044\n",
      "For n_clusters=9, The Silhouette Coefficient is 0.17197776034443088\n",
      "For n_clusters=10, The Silhouette Coefficient is 0.14834026455783147\n",
      "asa\n",
      "bgp\n",
      "designer\n",
      "eigrp\n",
      "ip\n",
      "ospf\n",
      "switches\n",
      "tcp\n",
      "vpn\n",
      "wan\n",
      "\n",
      "\n",
      "asa\n",
      "bgp\n",
      "designer\n",
      "eigrp\n",
      "ip\n",
      "ospf\n",
      "switches\n",
      "tcp\n",
      "vpn\n",
      "wan\n",
      "\n",
      "\n",
      "asa\n",
      "bgp\n",
      "designer\n",
      "eigrp\n",
      "ip\n",
      "ospf\n",
      "switches\n",
      "tcp\n",
      "vpn\n",
      "wan\n",
      "\n",
      "\n",
      "asa\n",
      "bgp\n",
      "designer\n",
      "eigrp\n",
      "ip\n",
      "ospf\n",
      "switches\n",
      "tcp\n",
      "vpn\n",
      "wan\n",
      "\n",
      "\n",
      "asa\n",
      "bgp\n",
      "designer\n",
      "eigrp\n",
      "firewall\n",
      "ip\n",
      "ospf\n",
      "switches\n",
      "tcp\n",
      "vpn\n",
      "wan\n",
      "\n",
      "\n",
      "asa\n",
      "bgp\n",
      "designer\n",
      "eigrp\n",
      "graphic\n",
      "ios\n",
      "ip\n",
      "lan\n",
      "ospf\n",
      "switches\n",
      "tcp\n",
      "vpn\n",
      "wan\n",
      "\n",
      "\n",
      "asa\n",
      "bgp\n",
      "designer\n",
      "eigrp\n",
      "ip\n",
      "ospf\n",
      "switches\n",
      "tcp\n",
      "vpn\n",
      "wan\n",
      "\n",
      "\n",
      "asa\n",
      "bgp\n",
      "designer\n",
      "eigrp\n",
      "ip\n",
      "ospf\n",
      "routers\n",
      "switches\n",
      "tcp\n",
      "vpn\n",
      "wan\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "manager.clusterData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.clustersToForm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "503\n"
     ]
    }
   ],
   "source": [
    "print(len(manager.kMeans.cluster_centers_[0]))\n",
    "print(len(manager.kMeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(manager.kMeans.labels_)\n",
    "# for cvNumber in manager.kMeans.labels_:\n",
    "#     for clusterNumber in range(manager.clustersToForm):\n",
    "#         if(cvNumber==clusterNumber):\n",
    "#             print(\"%d cv is in %d cluster\"%(cvNumber,clusterNumber))\n",
    "#             break\n",
    "# import pandas as pd\n",
    "# a = np.asarray([ [1,2,3], [4,5,6], [7,8,9] ])\n",
    "# print(type(a))\n",
    "# df = pd.DataFrame(manager.documentMatrix.toarray())\n",
    "# df.to_csv(\"file_path.csv\")\n",
    "# centroids=manager.kMeans.cluster_centers_\n",
    "# labels=manager.kMeans.labels_\n",
    "# print(centroids[0])\n",
    "# print(centroids[1])\n",
    "# print(len(centroids[2]))\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(len(manager.documentMatrix.toarray()))\n",
    "# print(len(manager.normalizedFeatureSet))\n",
    "# a = np.arange(6).reshape(-1,1)\n",
    "# print(centroids[0].shape)\n",
    "# x=centroids[0].reshape(-1,1)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#manager.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from ReliefF import ReliefF as rf\n",
    "# r1=rf(n_neighbors=manager.clustersToForm-1)\n",
    "# topfeatures=r1.fit_transform(centroids,labels)\n",
    "# print(topfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# x = [916,684,613,612,593,552,487,484,475,474,438,431,421,418,409,391,389,388,\n",
    "#     380,374,371,369,357,356,340,338,328,317,316,315,313,303,283,257,255,254,245,\n",
    "#     234,232,227,227,222,221,221,219,214,201,200,194,169,155,140]\n",
    "\n",
    "# kmeans = KMeans(n_clusters=4)\n",
    "# a = kmeans.fit(np.reshape(x,(len(x),1)))\n",
    "# centroids = kmeans.cluster_centers_\n",
    "\n",
    "# labels = kmeans.labels_\n",
    "\n",
    "# print(centroids)\n",
    "# print(labels)\n",
    "\n",
    "# colors = [\"g.\",\"r.\",\"y.\",\"b.\"]\n",
    "\n",
    "# for i in centroids:\n",
    "#     plt.plot( [0, len(x)-1],[i,i], \"k\" )\n",
    "# for i in range(len(x)):\n",
    "#     plt.plot(i, x[i], colors[labels[i]], markersize = 10)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "readCSVFile(manager.cvsFile)[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "# x = np.arange(9.).reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "# cols =  ['Class', 'Alcohol', 'MalicAcid', 'Ash', 'AlcalinityOfAsh', 'Magnesium', 'TotalPhenols', \n",
    "#          'Flavanoids', 'NonflavanoidPhenols', 'Proanthocyanins', 'ColorIntensity', \n",
    "#          'Hue', 'OD280/OD315', 'Proline']\n",
    "# data = pd.read_csv(url, names=cols)\n",
    "\n",
    "# Y = data['Class']          # Split off classifications\n",
    "\n",
    "# X = data.ix[:, 'Alcohol':] # Split off feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# a = [[1.2,'abc',3],[1.2,'werew',4],[1.4,'qew',2]]\n",
    "\n",
    "# my_df = pd.DataFrame(a)\n",
    "# r=[\"o\",\"t\",\"d\"]\n",
    "# i=[0,1,2]\n",
    "# my_df.to_csv('my_csv.csv', index=i, header=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
