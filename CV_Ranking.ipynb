{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class convertCVtoText:\n",
    "    @staticmethod\n",
    "    def startConversion(fileName):\n",
    "        import PyPDF2\n",
    "        pdfFileObj = open(fileName,'rb')     #'rb' for read binary mode\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        noOfPages=pdfReader.numPages\n",
    "        text=\"\"\n",
    "        for pages in range(0,pdfReader.numPages):\n",
    "            pageObj = pdfReader.getPage(pages)          #'9' is the page number\n",
    "            text+=pageObj.extractText()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class regularExp:\n",
    "    @staticmethod\n",
    "    def normalizeText(text):\n",
    "        norText=\"\"\n",
    "        returnText=\"\"\n",
    "        import re\n",
    "        norText+= re.sub(r'[^a-zA-Z ]',r' ',text)\n",
    "        returnText+=re.sub(' +',' ',norText)\n",
    "        return returnText\n",
    "    @staticmethod\n",
    "    def Stemmer(text):\n",
    "        from nltk.stem import PorterStemmer\n",
    "        import nltk\n",
    "        words=nltk.word_tokenize(text)\n",
    "        stemmer = PorterStemmer()\n",
    "        singles = [stemmer.stem(word) for word in words]\n",
    "        #print(singles)\n",
    "        singles=list(set(singles))\n",
    "        #print(singles)\n",
    "        stemmedText=\" \".join(singles)\n",
    "        #print(stemmedText)\n",
    "        return stemmedText\n",
    "       \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NLTKHelper:\n",
    "    @staticmethod\n",
    "    def findDocumentMatrix(totalCVText,minFrequency):\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        vectorizer=CountVectorizer(stop_words='english',min_df=minFrequency)\n",
    "        documentMatrix=vectorizer.fit_transform(totalCVText)\n",
    "        vocabulary=vectorizer.vocabulary_\n",
    "        return documentMatrix,vocabulary     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CV:\n",
    "     def __init__(self,path):\n",
    "            self.fileName=path\n",
    "            self.text=convertCVtoText.startConversion(self.fileName)\n",
    "            self.cleanText=regularExp.normalizeText(self.text)\n",
    "            self.stemedText=regularExp.Stemmer(self.cleanText)\n",
    "            #self.cleanTextNew=regularExp.normalizeText(self.stemedText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class databaseHandler:\n",
    "#     def __init__(self,password=\"ST.xavier51\",databaseName=\"cvRanking\"):\n",
    "#         import pymysql\n",
    "#         try:\n",
    "#             self.database=pymysql.connect(\"localhost\",\"root\",\"ST.xavier51\",\"cvRanking\")\n",
    "#             self.cursor = self.database.cursor()\n",
    "#         except Exception as e:\n",
    "#             print(\"error info %s\"%e)\n",
    "#     def entryTheCV(self,data_CV):\n",
    "#         try:\n",
    "# #             dataReturned=self.checkDuplication(data_CV[1])\n",
    "# #             if(len(dataReturned)==0):\n",
    "#                 add_CV=\"\"\"insert into recordentry\n",
    "#                     (checkRecord,recordname)\n",
    "#                     values(%s,%s)\"\"\"\n",
    "#     #             add_CV=\"\"\"insert into recordentry\n",
    "#     #                 (idrecordEntry,checkRecord,recordname)\n",
    "#     #                 values(%s,%s,%s)\"\"\"\n",
    "#                 #data_CV=(\"yes\",\"ram\")\n",
    "#                 print(data_CV)\n",
    "#                 self.cursor.execute(add_CV,data_CV)\n",
    "#                 self.database.commit()\n",
    "#                 print(\"CV name is entered in database\")\n",
    "#         except Exception as e:\n",
    "#             print(\"in entryTheCV\\t\"+str(e))\n",
    "#     def checkDuplication(self,name_CV):\n",
    "#         try:\n",
    "#             check_CV=\"\"\"select* from recordentry as re where re.recordname=%s\"\"\"\n",
    "#             self.cursor.execute(check_CV,name_CV)\n",
    "#             result = self.cursor.fetchall()\n",
    "#         except Exception as e:\n",
    "#             print(\"in process checkDuplication\\t\"+str(e))\n",
    "#         if(len(result)==0):  \n",
    "#             return False\n",
    "#         else:\n",
    "#             return True  \n",
    "#     def closeConnection(self):\n",
    "#         self.database.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CVManager:\n",
    "    def __init__(self):\n",
    "        self.CVAdded=None\n",
    "        #self.database=databaseHandler()\n",
    "        self.CVList=[]\n",
    "        self.CVPervoiusFileName=[]\n",
    "        self.CVFileName=[]\n",
    "        self.fileNamesWithPath=[]\n",
    "        self.CVTextColl=[]\n",
    "        self.CVTextCollTest=[]\n",
    "        self.documentMatrix=[]\n",
    "        self.vocabulary={}\n",
    "        self.documentMatrixTest=[]\n",
    "        self.vocabularyTest={}\n",
    "    def list_CVs(self,rootPath):\n",
    "            import os,json\n",
    "            try:\n",
    "                with open(\"CVNameList.json\",\"r\") as file:\n",
    "                    self.CVPervoiusFileName=json.load(file)\n",
    "                file.close()\n",
    "            except (FileNotFoundError, IOError):\n",
    "                print(\"CV has not been added yet.\\n Adding the CV\")\n",
    "            \n",
    "            for root, dirs, files in os.walk(rootPath):\n",
    "                for name in files:\n",
    "                    self.CVFileName.append(name)\n",
    "                    with open(\"CVNameList.json\",\"w\") as file:\n",
    "                        json.dump(self.CVFileName,file)\n",
    "                    file.close()\n",
    "                    self.fileNamesWithPath.append(os.path.join(root, name))\n",
    "    def collectCV(self):\n",
    "        self.checkCVList()\n",
    "        if(self.CVAdded):\n",
    "            for cvPath in self.fileNamesWithPath:\n",
    "                try:\n",
    "                    newCV=CV(cvPath)\n",
    "                    self.CVList.append(newCV)\n",
    "                    #print(\"%s named CV is already in database\"%cvName)\n",
    "                except Exception as e:\n",
    "                    print(cvPath)\n",
    "                    print(\"in collection of CV \\t\"+str(e))\n",
    "    def checkCVList(self):\n",
    "        if(set(self.CVFileName)& set(self.CVPervoiusFileName)):\n",
    "            #if common\n",
    "            print(\"all cv are added\")\n",
    "            self.CVAdded=False\n",
    "        else:\n",
    "            print(\"adding CV\")\n",
    "            self.CVAdded=True\n",
    "            \n",
    "    def collectCVText(self):\n",
    "        if(self.CVAdded):\n",
    "            for cv in self.CVList:\n",
    "                self.CVTextColl.append(cv.cleanText) \n",
    "                self.CVTextCollTest.append(cv.stemedText) \n",
    "    def findDocumentMatrix(self,minFrequency):\n",
    "        import json\n",
    "        try:\n",
    "            if(self.CVAdded):\n",
    "                self.collectCVText()\n",
    "                print(\"here\")\n",
    "                self.documentMatrix,self.vocabulary=NLTKHelper.findDocumentMatrix(self.CVTextColl,minFrequency)\n",
    "                self.documentMatrixTest,self.vocabularyTest=NLTKHelper.findDocumentMatrix(self.CVTextCollTest,minFrequency)\n",
    "                with open(\"wholeCVText.json\",\"w\") as file:\n",
    "                    json.dump(self.CVTextColl,file)\n",
    "                file.close()\n",
    "                with open(\"wholeCVTextTest.json\",\"w\") as file:\n",
    "                    json.dump(self.CVTextCollTest,file)\n",
    "                file.close()\n",
    "            else:\n",
    "                with open(\"wholeCVText.json\",\"r\") as file:\n",
    "                    self.CVTextColl=json.load(file)\n",
    "                file.close()\n",
    "                with open(\"wholeCVTextTest.json\",\"r\") as file:\n",
    "                    self.CVTextCollTest=json.load(file)\n",
    "                file.close()\n",
    "                self.documentMatrix,self.vocabulary=NLTKHelper.findDocumentMatrix(self.CVTextColl,minFrequency)\n",
    "                self.documentMatrixTest,self.vocabularyTest=NLTKHelper.findDocumentMatrix(self.CVTextCollTest,minFrequency)\n",
    "        except Exception as e:\n",
    "                print(\"in reading/writing of saved files \\t\"+str(e))\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manager=CVManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV has not been added yet.\n",
      " Adding the CV\n"
     ]
    }
   ],
   "source": [
    "manager.list_CVs(\"CV coll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding CV\n"
     ]
    }
   ],
   "source": [
    "manager.collectCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manager.findDocumentMatrix(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#manager.CVTextColl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manager.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manager.vocabularyTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for(k,v), (k2,v2) in zip(manager.vocabulary.items(), manager.vocabularyTest.items()):\n",
    "#     print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "re.sub(' +',' ','The     quick brown    fox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
